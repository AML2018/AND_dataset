{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Requirements\n"
     ]
    }
   ],
   "source": [
    "#python\n",
    "# coding: utf-8\n",
    "\n",
    "### Required Imports ###\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time, glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import cv2, os\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"Imported Requirements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HYPERPARAMETERS #####\n",
    "INPUT_LAYER_SHAPE_X = 150\n",
    "INPUT_LAYER_SHAPE_Y = 65\n",
    "KERNEL_SIZE = [5, 5]\n",
    "POOLING_SIZE = [2, 2]\n",
    "LAYER_1_FILTERS = 32\n",
    "LAYER_2_FILTERS = 64\n",
    "\n",
    "DENSE_LAYER_UNITS = 1024\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT = 0.4\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "### Specifies the number of steps the model will take. Can exceed the number of images to train ###\n",
    "TRAIN_STEPS = 200\n",
    "\n",
    "### Specifies the number of runs through the training data ###\n",
    "### None implies that the model will train till the number of steps specified ###\n",
    "NUM_EPOCHS = None\n",
    "\n",
    "### Training plus test data size ###\n",
    "DATA_SIZE = 100000\n",
    "\n",
    "MODEL_DIR = \"tmp/mnist_convnet_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Images\n",
      "Cropped Images\n",
      "150 65\n",
      "Resized Images\n",
      "Processed and Written Images\n",
      "Similar Sample generated\n",
      "Different Sample generated\n",
      "Subtracted data generated\n",
      "Split data into training and test\n",
      "321.1095094680786 seconds\n"
     ]
    }
   ],
   "source": [
    "def subtract_images(image1,image2):\n",
    "    return 255-np.array([[k-l if k > l else l-k for k,l in zip(i,j)] for i,j in zip(image1.tolist(),image2.tolist())])   \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## Import images\n",
    "mypath='AND_dataset\\\\Dataset[Without-Features]\\\\AND_Images[WithoutFeatures]'\n",
    "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "images = np.empty(len(onlyfiles), dtype=object)\n",
    "for n in range(0, len(onlyfiles)):\n",
    "    images[n] = cv2.imread( join(mypath,onlyfiles[n]),cv2.IMREAD_GRAYSCALE )\n",
    "print(\"Imported Images\")\n",
    "\n",
    "## Crop images ##\n",
    "images = [i[~np.all(i == 255, axis=1)][:,~np.all(i[~np.all(i == 255, axis = 1)] == 255, axis=0)] for i in images]\n",
    "print(\"Cropped Images\")\n",
    "\n",
    "## Resize images ##\n",
    "shapes = [i.shape for i in images]\n",
    "height = [i[0] for i in shapes]\n",
    "length = [i[1] for i in shapes]\n",
    "avg_height = int(sum(height)/len(height))\n",
    "avg_length = int(sum(length)/len(length))\n",
    "print(avg_length, avg_height)\n",
    "images = [cv2.resize(images[i],(avg_length, avg_height)) for i in range(len(images))]\n",
    "print(\"Resized Images\")\n",
    "\n",
    "## Write Processed images ##\n",
    "processed_directory = \"Processed/\"\n",
    "subtracted_directory = \"Subtracted/\"\n",
    "if not os.path.exists(processed_directory):\n",
    "    os.makedirs(processed_directory)\n",
    "if not os.path.exists(subtracted_directory):\n",
    "    os.makedirs(subtracted_directory)\n",
    "save = [cv2.imwrite(processed_directory+onlyfiles[i],images[i]) for i in range(len(images))]\n",
    "print(\"Processed and Written Images\")\n",
    "\n",
    "## Selecting similar sample ##\n",
    "authors = sorted(set([i.split(\"_\")[0][:4] for i in onlyfiles]))\n",
    "author_dict = {}\n",
    "\n",
    "for i in authors:\n",
    "    author_dict[i] = []\n",
    "continue_index = 0\n",
    "sorted_keys = sorted(author_dict.keys())\n",
    "for i in sorted_keys:\n",
    "    for j in onlyfiles[continue_index:]:\n",
    "        if i in j:\n",
    "            author_dict[i].append(j)\n",
    "        else:\n",
    "            continue_index = onlyfiles.index(j)\n",
    "            break\n",
    "\n",
    "permutated_dict = {}\n",
    "for i in authors:\n",
    "    permutated_dict[i] = []\n",
    "for i in author_dict.keys():\n",
    "    for r in itertools.product(author_dict[i], author_dict[i]):\n",
    "        if (r[0] != r[1]) and ([r[1],r[0]] not in permutated_dict[i]):\n",
    "            permutated_dict[i].append([r[0],r[1]])\n",
    "            \n",
    "similar = [j for i in permutated_dict.keys() for j in permutated_dict[i]]\n",
    "similar_sample = random.sample(similar,int(DATA_SIZE/2) if int(DATA_SIZE/2) < len(similar) else len(similar))\n",
    "print(\"Similar Sample generated\")\n",
    "\n",
    "## Selecting different sample ##\n",
    "different_keys = [i.split(\"*_*\") for i in set([\"*_*\".join(sorted([i,j])) for i,j in itertools.product(author_dict.keys(),author_dict.keys()) if i!=j])]\n",
    "diff_keys_sample = random.sample(different_keys,int(DATA_SIZE/2) if int(DATA_SIZE/2) < len(different_keys) else len(different_keys))\n",
    "different_sample = [[random.choice(author_dict[i[0]]),random.choice(author_dict[i[1]])] for i in diff_keys_sample]\n",
    "print(\"Different Sample generated\")\n",
    "\n",
    "## data ##\n",
    "similar_sample_data = [subtract_images(images[onlyfiles.index(i[0])],images[onlyfiles.index(i[1])]) for i in similar_sample]\n",
    "different_sample_data = [subtract_images(images[onlyfiles.index(i[0])],images[onlyfiles.index(i[1])]) for i in different_sample]\n",
    "print(\"Subtracted data generated\")\n",
    "\n",
    "## Save subtracted data ##\n",
    "\"\"\"\n",
    "subtracted_directory = \"Subtracted/\"\n",
    "if not os.path.exists(subtracted_directory):\n",
    "    os.makedirs(subtracted_directory)\n",
    "save = [cv2.imwrite(subtracted_directory+str(i)+ \"___\" +similar_sample[i][0].split(\".\")[0]+\"__\"+similar_sample[i][1],similar_sample_data[i]) for i in range(len(similar_sample_data))]\n",
    "save = [cv2.imwrite(subtracted_directory+str(50000+i)+ \"___\" +different_sample[i][0].split(\".\")[0]+\"__\"+different_sample[i][1],different_sample_data[i]) for i in range(len(different_sample_data))]\n",
    "print(\"Subtracted data saved\")\n",
    "\"\"\"\n",
    "\n",
    "## Train test split ##\n",
    "data = {}\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "data[\"x\"] = np.array(similar_sample_data + different_sample_data,dtype='float32')/255.0\n",
    "data[\"y\"] = np.array([1 for i in range(50000)] + [0 for i in range(50000)])\n",
    "train_data[\"x\"], test_data[\"x\"], train_data[\"y\"], test_data[\"y\"] = train_test_split(data[\"x\"], data[\"y\"], test_size=0.2)\n",
    "print(\"Split data into training and test\")\n",
    "\n",
    "## Time taken ##\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference: https://www.tensorflow.org/tutorials/layers ###\n",
    "\n",
    "### Model function that trains and evaluates the model ###\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, INPUT_LAYER_SHAPE_X, INPUT_LAYER_SHAPE_Y, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=LAYER_1_FILTERS,\n",
    "      kernel_size=KERNEL_SIZE,\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=POOLING_SIZE, strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=LAYER_2_FILTERS,\n",
    "      kernel_size=KERNEL_SIZE,\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=POOLING_SIZE, strides=2)\n",
    "    \n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, pool2.shape[1] * pool2.shape[2] * LAYER_2_FILTERS])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=DENSE_LAYER_UNITS, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=DROPOUT, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    " \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_task_type': 'worker', '_task_id': 0, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_is_chief': True, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_session_config': None, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C0A4FD44A8>, '_master': '', '_model_dir': 'tmp/mnist_convnet_model', '_log_step_count_steps': 100, '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.43404138  0.56595868]\n",
      " [ 0.46769792  0.53230208]\n",
      " [ 0.45110053  0.54889947]\n",
      " [ 0.5460822   0.4539178 ]\n",
      " [ 0.44865575  0.55134416]\n",
      " [ 0.55966717  0.44033283]\n",
      " [ 0.4909972   0.50900286]\n",
      " [ 0.43510962  0.56489044]\n",
      " [ 0.42344034  0.57655966]\n",
      " [ 0.42906693  0.57093298]\n",
      " [ 0.38785946  0.6121406 ]\n",
      " [ 0.49802417  0.50197583]\n",
      " [ 0.40766412  0.59233582]\n",
      " [ 0.57370079  0.42629915]\n",
      " [ 0.4656873   0.53431267]\n",
      " [ 0.48819104  0.51180893]\n",
      " [ 0.34948224  0.65051776]\n",
      " [ 0.42955989  0.57044011]\n",
      " [ 0.35827088  0.64172912]\n",
      " [ 0.47514778  0.52485222]\n",
      " [ 0.45573738  0.54426259]\n",
      " [ 0.39242172  0.60757834]\n",
      " [ 0.52389646  0.47610351]\n",
      " [ 0.39546639  0.60453367]\n",
      " [ 0.40009576  0.5999043 ]\n",
      " [ 0.53070021  0.46929976]\n",
      " [ 0.46749207  0.5325079 ]\n",
      " [ 0.50550973  0.4944903 ]\n",
      " [ 0.53248107  0.4675189 ]\n",
      " [ 0.44724005  0.55275995]\n",
      " [ 0.42430291  0.57569712]\n",
      " [ 0.52038842  0.47961161]\n",
      " [ 0.45816809  0.54183191]\n",
      " [ 0.5243485   0.4756515 ]\n",
      " [ 0.45627326  0.54372674]\n",
      " [ 0.54329151  0.45670846]\n",
      " [ 0.4362253   0.56377465]\n",
      " [ 0.52393806  0.47606194]\n",
      " [ 0.52868915  0.47131085]\n",
      " [ 0.46389371  0.53610635]\n",
      " [ 0.4872483   0.5127517 ]\n",
      " [ 0.41273811  0.58726192]\n",
      " [ 0.48874539  0.51125461]\n",
      " [ 0.44387749  0.55612254]\n",
      " [ 0.41152453  0.58847547]\n",
      " [ 0.3884902   0.6115098 ]\n",
      " [ 0.38413602  0.61586398]\n",
      " [ 0.41866407  0.58133596]\n",
      " [ 0.3849844   0.61501557]\n",
      " [ 0.46025833  0.53974169]\n",
      " [ 0.52545726  0.47454277]\n",
      " [ 0.43718851  0.56281149]\n",
      " [ 0.4872711   0.51272887]\n",
      " [ 0.44728085  0.55271918]\n",
      " [ 0.43547732  0.56452268]\n",
      " [ 0.38078946  0.61921048]\n",
      " [ 0.51512659  0.48487335]\n",
      " [ 0.39566493  0.60433507]\n",
      " [ 0.48125809  0.51874191]\n",
      " [ 0.50049585  0.49950415]\n",
      " [ 0.38944957  0.6105504 ]\n",
      " [ 0.37252086  0.62747914]\n",
      " [ 0.38718805  0.61281198]\n",
      " [ 0.426173    0.57382709]\n",
      " [ 0.44998172  0.55001825]\n",
      " [ 0.46859986  0.53140014]\n",
      " [ 0.48278162  0.51721841]\n",
      " [ 0.44346416  0.55653578]\n",
      " [ 0.49376601  0.50623393]\n",
      " [ 0.46176869  0.53823137]\n",
      " [ 0.5158053   0.48419467]\n",
      " [ 0.39152965  0.60847044]\n",
      " [ 0.43430761  0.56569242]\n",
      " [ 0.52131343  0.4786866 ]\n",
      " [ 0.38178778  0.61821228]\n",
      " [ 0.47209778  0.52790213]\n",
      " [ 0.41828954  0.58171046]\n",
      " [ 0.44797426  0.55202579]\n",
      " [ 0.46684226  0.53315777]\n",
      " [ 0.53752875  0.46247119]\n",
      " [ 0.34109762  0.65890235]\n",
      " [ 0.39885324  0.60114682]\n",
      " [ 0.4497954   0.55020458]\n",
      " [ 0.50214338  0.49785662]\n",
      " [ 0.42488375  0.57511628]\n",
      " [ 0.44377789  0.55622208]\n",
      " [ 0.46615183  0.53384817]\n",
      " [ 0.49428499  0.50571501]\n",
      " [ 0.43082282  0.56917715]\n",
      " [ 0.48439279  0.51560724]\n",
      " [ 0.47146735  0.52853262]\n",
      " [ 0.49662852  0.50337154]\n",
      " [ 0.39563605  0.60436398]\n",
      " [ 0.55618435  0.44381571]\n",
      " [ 0.48612809  0.51387197]\n",
      " [ 0.48383832  0.51616162]\n",
      " [ 0.47368816  0.52631181]\n",
      " [ 0.47571811  0.52428186]\n",
      " [ 0.43434146  0.56565857]\n",
      " [ 0.4960269   0.50397301]]\n",
      "INFO:tensorflow:loss = 0.692868, step = 1\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=MODEL_DIR)\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "### Logging to save progress. Checkpointing to restart from whenever necessary ###\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "### Feeding data to the model for running ###\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data[\"x\"]},\n",
    "    y=train_data[\"y\"],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    shuffle=True)\n",
    "\n",
    "### Training starts ###\n",
    "start_time = time.time()\n",
    "mnist_classifier.train(input_fn=train_input_fn,steps=TRAIN_STEPS,hooks=[logging_hook])\n",
    "print(\"Time taken to train =\", float((time.time() - start_time)/60.0), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Training complete #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Testing the trained model ###\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_data[\"x\"]},\n",
    "    y=test_data[\"y\"],\n",
    "    num_epochs=10,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(\" \")\n",
    "\n",
    "##Printing accuracy\n",
    "print(\"Accuracy\", eval_results[\"accuracy\"])\n",
    "\n",
    "## printing loss\n",
    "print(\"Loss\",eval_results[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# import zipfile\n",
    "# zip_ref = zipfile.ZipFile(\"AND_dataset.zip\", 'r')\n",
    "# zip_ref.extractall(os.getcwd())\n",
    "# zip_ref.close()\n",
    "print(\"Starting\")\n",
    "#Directory locations for the code\n",
    "image_path = \"Data\\\\img_align_celeba\"\n",
    "\n",
    "#Cropped Output\n",
    "output_path = \"Data\\\\cropped_faces\"\n",
    "if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "        \n",
    "output_labels = \"Data\\\\glasses.csv\"\n",
    "\n",
    "### place to save the model ###\n",
    "MODEL_DIR = \"tmp/mnist_convnet_model\"\n",
    "\n",
    "def import_data(start,end):\n",
    "    #Eyeglasses label\n",
    "    feature = pd.read_csv(output_labels)\n",
    "    eye_glasses = feature[[\"Images\",\"Eyeglasses\"]]\n",
    "\n",
    "    ### Changing -1 to 0 in the labels ###\n",
    "    Y_labels = list(feature.Eyeglasses)\n",
    "    Y_labels = np.array([i if i == 1 else 0 for i in Y_labels])[start:end]\n",
    "\n",
    "    #Importing images as numpy objects\n",
    "    SCALE = \"L\"\n",
    "    X_REZ = 28\n",
    "    Y_REZ = 28\n",
    "\n",
    "    ### Import and resize image ###\n",
    "    def resizer(path,scale=\"L\",resize_x=28,resize_y=28):\n",
    "        return np.array(Image.open(path).convert(scale).resize((resize_x,resize_y), Image.ANTIALIAS)).ravel().tolist()\n",
    "\n",
    "    ### List of path to cropped images\n",
    "    dirs_list = glob.glob(output_path+\"\\\\*.jpg\")[start:end]\n",
    "\n",
    "    ### Import all images in a directory ###\n",
    "    train_img = np.array([resizer(i,SCALE,X_REZ,Y_REZ) for i in dirs_list],dtype='float32')/255.0\n",
    "\n",
    "    ### dictionary of images and their labels ###\n",
    "    data = {}\n",
    "    data[\"x\"] = train_img\n",
    "    data[\"y\"] = Y_labels\n",
    "\n",
    "    return data\n",
    "\n",
    "#### Range of images to be imported to train ####\n",
    "data_length = 2000\n",
    "\n",
    "data_start_index = 0\n",
    "data_end_index = data_start_index + data_length\n",
    "### importing training data ###\n",
    "data = import_data(data_start_index,data_end_index)\n",
    "print(data)\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "\n",
    "### Splitting the data into training and testing ###\n",
    "train_data[\"x\"], test_data[\"x\"], train_data[\"y\"], test_data[\"y\"] = train_test_split(data[\"x\"], data[\"y\"], test_size=0.2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
